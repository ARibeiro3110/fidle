{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<img width=\"800px\" src=\"../fidle/img/00-Fidle-header-01.svg\"></img>\n",
    "\n",
    "# <!-- TITLE --> [DCGAN01] - A first DCGAN to Draw a Sheep\n",
    "<!-- DESC --> Episode 1 : Draw me a sheep, revisited with a DCGAN\n",
    "<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n",
    "\n",
    "## Objectives :\n",
    " - Build and train a DCGAN model with the Quick Draw dataset\n",
    " - Understanding DCGAN\n",
    "\n",
    "The [Quick draw dataset](https://quickdraw.withgoogle.com/data) contains about 50.000.000 drawings, made by real people...  \n",
    "We are using a subset of 117.555 of Sheep drawings  \n",
    "To get the dataset : [https://github.com/googlecreativelab/quickdraw-dataset](https://github.com/googlecreativelab/quickdraw-dataset)  \n",
    "To get the subdataset in numpy bitmap file : [https://console.cloud.google.com/storage/quickdraw_dataset/full/numpy_bitmap](https://console.cloud.google.com/storage/quickdraw_dataset/full/numpy_bitmap) (94.3 Mo)\n",
    "\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Have a look to the dataset\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Follow the learning process with Tensorboard\n",
    "\n",
    "## Acknowledgements :\n",
    "Thanks to **FranÃ§ois Chollet** who is at the base of this example.  \n",
    "See : [https://keras.io/examples/](https://keras.io/examples/)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Init python stuff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from modules.models    import DCGAN\n",
    "from modules.callbacks import ImagesCallback\n",
    "\n",
    "sys.path.append('..')\n",
    "import fidle.pwk as pwk\n",
    "\n",
    "run_dir = './run/DCGAN.001'                  # Output directory\n",
    "datasets_dir = pwk.init('DCGAN01', run_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_dim = 128\n",
    "\n",
    "scale      = .1\n",
    "epochs     = 5\n",
    "batch_size = 32\n",
    "num_img    = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Override parameters (batch mode) - Just forget this cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pwk.override('latent_dim', 'epochs', 'batch_size', 'num_img', 'scale')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Load dataset and have a look \n",
    "Load sheeps as numpy bitmaps..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load dataset\n",
    "x_data = np.load(datasets_dir+'/QuickDraw/origine/full_numpy_bitmap_sheep.npy')\n",
    "print(x_data.shape)\n",
    "\n",
    "# Rescale\n",
    "n=int(scale*len(x_data))\n",
    "x_data = x_data[:n]\n",
    "print(x_data.shape)\n",
    "\n",
    "# Normalize, reshape and shuffle\n",
    "x_data = x_data/255\n",
    "x_data = x_data.reshape(-1,28,28,1)\n",
    "np.random.shuffle(x_data)\n",
    "print(x_data.shape)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "...and have a look :  \n",
    "Note : These sheep are sheep drawn ... by real humans!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pwk.plot_images(x_data.reshape(-1,28,28), indices=range(72), columns=12, x_size=1, y_size=1, y_padding=0,spines_alpha=0, save_as='01-Sheeps')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4 - Create a discriminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# discriminator = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(28, 28, 1)),\n",
    "#         layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(1, activation=\"sigmoid\"),\n",
    "#     ],\n",
    "#     name=\"discriminator\",\n",
    "# )\n",
    "# discriminator.summary()\n",
    "\n",
    "\n",
    "inputs    = keras.Input(shape=(28, 28, 1))\n",
    "x         = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(inputs)\n",
    "x         = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x         = layers.Flatten()(x)\n",
    "x         = layers.Dense(16, activation=\"relu\")(x)\n",
    "z         = layers.Dense(latent_dim)(x)\n",
    "\n",
    "discriminator = keras.Model(inputs, z, name=\"encoder\")\n",
    "discriminator.summary()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5 - Create a generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generator = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(latent_dim,)),\n",
    "#         layers.Dense(7 * 7 * 64),\n",
    "#         layers.Reshape((7, 7, 64)),\n",
    "#         layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2DTranspose(256, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "#     ],\n",
    "#     name=\"generator\",\n",
    "# )\n",
    "# generator.summary()\n",
    "\n",
    "\n",
    "inputs  = keras.Input(shape=(latent_dim,))\n",
    "x       = layers.Dense(7 * 7 * 64, activation=\"relu\")(inputs)\n",
    "x       = layers.Reshape((7, 7, 64))(x)\n",
    "x       = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x       = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "generator = keras.Model(inputs, outputs, name=\"decoder\")\n",
    "generator.summary()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6 - Create our DCGAN !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!rm $run_dir/images/*.jpg >/dev/null 2>&1 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gan.compile(\n",
    "    discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    generator_optimizer     = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_function           = keras.losses.BinaryCrossentropy(),\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imagesCallback = ImagesCallback(num_img=num_img, latent_dim=latent_dim, run_dir=f'{run_dir}/images')\n",
    "\n",
    "history = gan.fit( x_data, epochs=epochs, batch_size=batch_size, callbacks=[imagesCallback] )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 7 - History"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pwk.plot_history(history,  plot={'loss':['d_loss','g_loss']}, save_as='01-history')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imgs=[]\n",
    "for epoch in range(0,epochs,2):\n",
    "    for i in range(5):\n",
    "        filename = f'{run_dir}/images/image-{epoch:03d}-{i:02d}.jpg'\n",
    "        img      = io.imread(filename)\n",
    "        imgs.append(img)      \n",
    "\n",
    "pwk.plot_images(imgs, None, indices='all', columns=5, x_size=1.5,y_size=1.5, interpolation=None, y_padding=0, spines_alpha=0, save_as='04-learning')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('fidle': conda)"
  },
  "interpreter": {
   "hash": "0d4eaa39e9afca7e4a329c71e6d11fd895be2163d24367e6af7052bf3ebf4932"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}