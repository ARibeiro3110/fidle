{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"../fidle/img/00-Fidle-header-01.svg\"></img>\n",
    "\n",
    "# <!-- TITLE --> [VAE1] - Variational AutoEncoder (VAE) with MNIST\n",
    "<!-- DESC --> Episode 1 : Model construction and Training\n",
    "\n",
    "<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n",
    "\n",
    "## Objectives :\n",
    " - Understanding and implementing a **variational autoencoder** neurals network (VAE)\n",
    " - Understanding a more **advanced programming model**\n",
    "\n",
    "The calculation needs being important, it is preferable to use a very simple dataset such as MNIST to start with.\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Follow the learning process with Tensorboard\n",
    "\n",
    "----\n",
    "## Bug Note :\n",
    "**Works in tf 2.0, but not in 2.2/2.3**  \n",
    "\n",
    "See :\n",
    " - https://github.com/tensorflow/tensorflow/issues/34944  \n",
    " - https://github.com/tensorflow/probability/issues/519  \n",
    "\n",
    "Bypass :\n",
    " - Use tf 2.0\n",
    " - Add `tf.config.experimental_run_functions_eagerly(True)` before compilation...  \n",
    "Works fine in versions 2.2, 2.3 but with horrible perf. (7s -> 1'50s)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Init python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIDLE 2020 - Variational AutoEncoder (VAE)\n",
      "TensorFlow version   : 2.0.0\n",
      "VAE version          : 1.28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, importlib\n",
    "\n",
    "import modules.vae\n",
    "import modules.loader_MNIST\n",
    "\n",
    "from modules.vae          import VariationalAutoencoder\n",
    "from modules.loader_MNIST import Loader_MNIST\n",
    "\n",
    "VariationalAutoencoder.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "Normalized.\n",
      "Reshaped to (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = Loader_MNIST.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Get VAE model\n",
    "Nous allons instancier notre modèle VAE.  \n",
    "Ce dernier est défini avec une classe python pour alléger notre code.  \n",
    "La description de nos deux réseaux est donnée en paramètre.  \n",
    "Notre modèle sera sauvegardé dans le dossier : ./run/<tag>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "Outputs will be in  : ./run/MNIST.001\n",
      "\n",
      " ---------- Encoder -------------------------------------------------- \n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105,220\n",
      "Trainable params: 105,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " ---------- Encoder -------------------------------------------------- \n",
      "\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Config saved in     : ./run/MNIST.001/models/vae_config.json\n"
     ]
    }
   ],
   "source": [
    "tag = 'MNIST.001'\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "z_dim       = 2\n",
    "verbose     = 1\n",
    "\n",
    "encoder= [ {'type':'Conv2D',          'filters':32, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'}\n",
    "         ]\n",
    "\n",
    "decoder= [ {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':32, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':1,  'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'sigmoid'}\n",
    "         ]\n",
    "\n",
    "vae = modules.vae.VariationalAutoencoder(input_shape    = input_shape, \n",
    "                                         encoder_layers = encoder, \n",
    "                                         decoder_layers = decoder,\n",
    "                                         z_dim          = z_dim, \n",
    "                                         verbose        = verbose,\n",
    "                                         run_tag        = tag)\n",
    "vae.save(model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled.\n"
     ]
    }
   ],
   "source": [
    "r_loss_factor = 1000\n",
    "\n",
    "vae.compile( optimizer='adam', r_loss_factor=r_loss_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train\n",
    "Durations :\n",
    " - IDRIS on Jean Zay (V100) : 391.89 sec. - 0:06:31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size        = 100\n",
    "epochs            = 100\n",
    "initial_epoch     = 0\n",
    "k_size            = 1      # 1 mean using 100% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "  100/60000 [..............................] - ETA: 23:20 - loss: 231.3020 - vae_r_loss: 231.3009 - vae_kl_loss: 0.0012WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.204730). Check your callbacks.\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 64.2543 - vae_r_loss: 61.7709 - vae_kl_loss: 2.4833 - val_loss: 52.9003 - val_vae_r_loss: 49.1967 - val_vae_kl_loss: 3.7036\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 51.2057 - vae_r_loss: 47.0966 - vae_kl_loss: 4.1091 - val_loss: 49.8133 - val_vae_r_loss: 45.4482 - val_vae_kl_loss: 4.3652\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 49.1852 - vae_r_loss: 44.6769 - vae_kl_loss: 4.5083 - val_loss: 48.4312 - val_vae_r_loss: 43.8612 - val_vae_kl_loss: 4.5701\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 48.0964 - vae_r_loss: 43.4097 - vae_kl_loss: 4.6867 - val_loss: 48.0231 - val_vae_r_loss: 43.2757 - val_vae_kl_loss: 4.7474\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 47.3871 - vae_r_loss: 42.5845 - vae_kl_loss: 4.8026 - val_loss: 47.2221 - val_vae_r_loss: 42.6021 - val_vae_kl_loss: 4.6200\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 46.8934 - vae_r_loss: 41.9934 - vae_kl_loss: 4.9000 - val_loss: 46.9390 - val_vae_r_loss: 41.8111 - val_vae_kl_loss: 5.1278\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 46.4743 - vae_r_loss: 41.4820 - vae_kl_loss: 4.9924 - val_loss: 46.2958 - val_vae_r_loss: 41.2182 - val_vae_kl_loss: 5.0776\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 46.1191 - vae_r_loss: 41.0788 - vae_kl_loss: 5.0403 - val_loss: 46.2291 - val_vae_r_loss: 41.0391 - val_vae_kl_loss: 5.1900\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 45.7910 - vae_r_loss: 40.7070 - vae_kl_loss: 5.0840 - val_loss: 45.9437 - val_vae_r_loss: 40.7491 - val_vae_kl_loss: 5.1946\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 45.5396 - vae_r_loss: 40.3924 - vae_kl_loss: 5.1471 - val_loss: 45.9343 - val_vae_r_loss: 40.7377 - val_vae_kl_loss: 5.1966\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 45.2789 - vae_r_loss: 40.0885 - vae_kl_loss: 5.1904 - val_loss: 45.4758 - val_vae_r_loss: 40.3435 - val_vae_kl_loss: 5.1323\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 45.1051 - vae_r_loss: 39.8695 - vae_kl_loss: 5.2355 - val_loss: 45.4878 - val_vae_r_loss: 40.1696 - val_vae_kl_loss: 5.3181\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 44.8887 - vae_r_loss: 39.6061 - vae_kl_loss: 5.2826 - val_loss: 45.1749 - val_vae_r_loss: 39.8426 - val_vae_kl_loss: 5.3323\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 44.7158 - vae_r_loss: 39.3846 - vae_kl_loss: 5.3312 - val_loss: 45.0787 - val_vae_r_loss: 39.6166 - val_vae_kl_loss: 5.4621\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 44.5586 - vae_r_loss: 39.2236 - vae_kl_loss: 5.3350 - val_loss: 44.8298 - val_vae_r_loss: 39.6147 - val_vae_kl_loss: 5.2150\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 44.3802 - vae_r_loss: 39.0108 - vae_kl_loss: 5.3694 - val_loss: 44.6618 - val_vae_r_loss: 39.2968 - val_vae_kl_loss: 5.3649\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 44.2723 - vae_r_loss: 38.8741 - vae_kl_loss: 5.3981 - val_loss: 44.8400 - val_vae_r_loss: 39.4563 - val_vae_kl_loss: 5.3837\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 44.1674 - vae_r_loss: 38.7606 - vae_kl_loss: 5.4068 - val_loss: 44.7985 - val_vae_r_loss: 39.3888 - val_vae_kl_loss: 5.4097\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 44.0322 - vae_r_loss: 38.5949 - vae_kl_loss: 5.4373 - val_loss: 44.6795 - val_vae_r_loss: 39.3680 - val_vae_kl_loss: 5.3115\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.9153 - vae_r_loss: 38.4687 - vae_kl_loss: 5.4466 - val_loss: 44.5306 - val_vae_r_loss: 39.0573 - val_vae_kl_loss: 5.4733\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.8438 - vae_r_loss: 38.3777 - vae_kl_loss: 5.4661 - val_loss: 44.5254 - val_vae_r_loss: 39.0821 - val_vae_kl_loss: 5.4433\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.7249 - vae_r_loss: 38.2270 - vae_kl_loss: 5.4978 - val_loss: 44.4218 - val_vae_r_loss: 38.9123 - val_vae_kl_loss: 5.5095\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.6932 - vae_r_loss: 38.1905 - vae_kl_loss: 5.5027 - val_loss: 44.7400 - val_vae_r_loss: 39.4295 - val_vae_kl_loss: 5.3105\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.6025 - vae_r_loss: 38.0754 - vae_kl_loss: 5.5271 - val_loss: 44.1321 - val_vae_r_loss: 38.5209 - val_vae_kl_loss: 5.6112\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.4873 - vae_r_loss: 37.9447 - vae_kl_loss: 5.5426 - val_loss: 44.4036 - val_vae_r_loss: 38.8846 - val_vae_kl_loss: 5.5190\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.3999 - vae_r_loss: 37.8558 - vae_kl_loss: 5.5441 - val_loss: 44.2643 - val_vae_r_loss: 38.8511 - val_vae_kl_loss: 5.4132\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.3879 - vae_r_loss: 37.8274 - vae_kl_loss: 5.5606 - val_loss: 44.1832 - val_vae_r_loss: 38.7677 - val_vae_kl_loss: 5.4155\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.2868 - vae_r_loss: 37.7082 - vae_kl_loss: 5.5785 - val_loss: 44.3540 - val_vae_r_loss: 38.8401 - val_vae_kl_loss: 5.5138\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.1959 - vae_r_loss: 37.6151 - vae_kl_loss: 5.5807 - val_loss: 44.1458 - val_vae_r_loss: 38.7440 - val_vae_kl_loss: 5.4018\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.2025 - vae_r_loss: 37.6125 - vae_kl_loss: 5.5900 - val_loss: 44.0534 - val_vae_r_loss: 38.6051 - val_vae_kl_loss: 5.4484\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 43.1147 - vae_r_loss: 37.4968 - vae_kl_loss: 5.6179 - val_loss: 44.0018 - val_vae_r_loss: 38.4451 - val_vae_kl_loss: 5.5567\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 43.0382 - vae_r_loss: 37.4231 - vae_kl_loss: 5.6151 - val_loss: 44.0717 - val_vae_r_loss: 38.4346 - val_vae_kl_loss: 5.6371\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 43.0075 - vae_r_loss: 37.3852 - vae_kl_loss: 5.6223 - val_loss: 43.9579 - val_vae_r_loss: 38.3620 - val_vae_kl_loss: 5.5959\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.9493 - vae_r_loss: 37.3046 - vae_kl_loss: 5.6447 - val_loss: 43.9678 - val_vae_r_loss: 38.6328 - val_vae_kl_loss: 5.3351\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.8854 - vae_r_loss: 37.2427 - vae_kl_loss: 5.6427 - val_loss: 44.0184 - val_vae_r_loss: 38.2289 - val_vae_kl_loss: 5.7894\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 42.8633 - vae_r_loss: 37.2043 - vae_kl_loss: 5.6590 - val_loss: 43.9505 - val_vae_r_loss: 38.4289 - val_vae_kl_loss: 5.5216\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.8121 - vae_r_loss: 37.1433 - vae_kl_loss: 5.6688 - val_loss: 44.0720 - val_vae_r_loss: 38.3158 - val_vae_kl_loss: 5.7562\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 42.7729 - vae_r_loss: 37.0933 - vae_kl_loss: 5.6796 - val_loss: 43.9354 - val_vae_r_loss: 38.2530 - val_vae_kl_loss: 5.6825\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.7009 - vae_r_loss: 37.0158 - vae_kl_loss: 5.6851 - val_loss: 43.9757 - val_vae_r_loss: 38.3211 - val_vae_kl_loss: 5.6547\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.6597 - vae_r_loss: 36.9727 - vae_kl_loss: 5.6870 - val_loss: 43.9979 - val_vae_r_loss: 38.3241 - val_vae_kl_loss: 5.6738\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 42.6643 - vae_r_loss: 36.9573 - vae_kl_loss: 5.7070 - val_loss: 43.8959 - val_vae_r_loss: 38.0727 - val_vae_kl_loss: 5.8232\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 42.6094 - vae_r_loss: 36.9091 - vae_kl_loss: 5.7003 - val_loss: 43.7527 - val_vae_r_loss: 38.0132 - val_vae_kl_loss: 5.7396\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.5943 - vae_r_loss: 36.8753 - vae_kl_loss: 5.7190 - val_loss: 44.2513 - val_vae_r_loss: 38.7346 - val_vae_kl_loss: 5.5166\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.5383 - vae_r_loss: 36.8210 - vae_kl_loss: 5.7174 - val_loss: 43.9450 - val_vae_r_loss: 38.3041 - val_vae_kl_loss: 5.6410\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.4976 - vae_r_loss: 36.7647 - vae_kl_loss: 5.7328 - val_loss: 43.8147 - val_vae_r_loss: 38.0132 - val_vae_kl_loss: 5.8015\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.4661 - vae_r_loss: 36.7304 - vae_kl_loss: 5.7358 - val_loss: 43.7803 - val_vae_r_loss: 37.9472 - val_vae_kl_loss: 5.8331\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.4550 - vae_r_loss: 36.7013 - vae_kl_loss: 5.7537 - val_loss: 43.7559 - val_vae_r_loss: 37.9233 - val_vae_kl_loss: 5.8325\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.4446 - vae_r_loss: 36.6954 - vae_kl_loss: 5.7491 - val_loss: 43.8857 - val_vae_r_loss: 38.3286 - val_vae_kl_loss: 5.5571\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 42.3392 - vae_r_loss: 36.5929 - vae_kl_loss: 5.7463 - val_loss: 43.7458 - val_vae_r_loss: 38.0185 - val_vae_kl_loss: 5.7273\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.3563 - vae_r_loss: 36.5882 - vae_kl_loss: 5.7680 - val_loss: 43.8635 - val_vae_r_loss: 38.3168 - val_vae_kl_loss: 5.5467\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.2795 - vae_r_loss: 36.5151 - vae_kl_loss: 5.7644 - val_loss: 43.8254 - val_vae_r_loss: 38.0452 - val_vae_kl_loss: 5.7802\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 42.2664 - vae_r_loss: 36.5060 - vae_kl_loss: 5.7604 - val_loss: 43.6070 - val_vae_r_loss: 37.8889 - val_vae_kl_loss: 5.7181\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.2173 - vae_r_loss: 36.4402 - vae_kl_loss: 5.7771 - val_loss: 43.8760 - val_vae_r_loss: 38.1647 - val_vae_kl_loss: 5.7113\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.2542 - vae_r_loss: 36.4783 - vae_kl_loss: 5.7759 - val_loss: 43.7798 - val_vae_r_loss: 38.0381 - val_vae_kl_loss: 5.7416\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.1756 - vae_r_loss: 36.3872 - vae_kl_loss: 5.7884 - val_loss: 43.6665 - val_vae_r_loss: 37.7873 - val_vae_kl_loss: 5.8791\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.1478 - vae_r_loss: 36.3798 - vae_kl_loss: 5.7681 - val_loss: 43.8873 - val_vae_r_loss: 38.0000 - val_vae_kl_loss: 5.8872\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.1221 - vae_r_loss: 36.3316 - vae_kl_loss: 5.7905 - val_loss: 43.7110 - val_vae_r_loss: 37.9034 - val_vae_kl_loss: 5.8076\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.1140 - vae_r_loss: 36.3114 - vae_kl_loss: 5.8026 - val_loss: 43.7163 - val_vae_r_loss: 37.9340 - val_vae_kl_loss: 5.7824\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.0872 - vae_r_loss: 36.2736 - vae_kl_loss: 5.8136 - val_loss: 43.6869 - val_vae_r_loss: 37.8728 - val_vae_kl_loss: 5.8141\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.0810 - vae_r_loss: 36.2625 - vae_kl_loss: 5.8184 - val_loss: 43.7259 - val_vae_r_loss: 37.9156 - val_vae_kl_loss: 5.8103\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.0468 - vae_r_loss: 36.2302 - vae_kl_loss: 5.8166 - val_loss: 43.7498 - val_vae_r_loss: 37.8267 - val_vae_kl_loss: 5.9231\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 42.0145 - vae_r_loss: 36.1916 - vae_kl_loss: 5.8229 - val_loss: 43.7140 - val_vae_r_loss: 37.8304 - val_vae_kl_loss: 5.8835\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 42.0032 - vae_r_loss: 36.1780 - vae_kl_loss: 5.8252 - val_loss: 43.7475 - val_vae_r_loss: 37.8840 - val_vae_kl_loss: 5.8635\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.9338 - vae_r_loss: 36.1049 - vae_kl_loss: 5.8289 - val_loss: 43.6136 - val_vae_r_loss: 37.8724 - val_vae_kl_loss: 5.7413\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.9362 - vae_r_loss: 36.1025 - vae_kl_loss: 5.8337 - val_loss: 43.6487 - val_vae_r_loss: 37.8507 - val_vae_kl_loss: 5.7980\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 41.8900 - vae_r_loss: 36.0639 - vae_kl_loss: 5.8261 - val_loss: 43.5734 - val_vae_r_loss: 37.7662 - val_vae_kl_loss: 5.8072\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8897 - vae_r_loss: 36.0485 - vae_kl_loss: 5.8413 - val_loss: 43.5914 - val_vae_r_loss: 37.8426 - val_vae_kl_loss: 5.7488\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8992 - vae_r_loss: 36.0566 - vae_kl_loss: 5.8426 - val_loss: 43.5969 - val_vae_r_loss: 37.8075 - val_vae_kl_loss: 5.7893\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8573 - vae_r_loss: 36.0016 - vae_kl_loss: 5.8557 - val_loss: 43.8489 - val_vae_r_loss: 38.0409 - val_vae_kl_loss: 5.8079\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8076 - vae_r_loss: 35.9602 - vae_kl_loss: 5.8474 - val_loss: 43.6968 - val_vae_r_loss: 37.9238 - val_vae_kl_loss: 5.7730\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8028 - vae_r_loss: 35.9475 - vae_kl_loss: 5.8553 - val_loss: 43.7155 - val_vae_r_loss: 38.1099 - val_vae_kl_loss: 5.6056\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.8149 - vae_r_loss: 35.9601 - vae_kl_loss: 5.8548 - val_loss: 43.7084 - val_vae_r_loss: 37.9777 - val_vae_kl_loss: 5.7306\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.7663 - vae_r_loss: 35.8984 - vae_kl_loss: 5.8679 - val_loss: 43.7315 - val_vae_r_loss: 37.8491 - val_vae_kl_loss: 5.8824\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.7511 - vae_r_loss: 35.8783 - vae_kl_loss: 5.8727 - val_loss: 43.6386 - val_vae_r_loss: 37.8350 - val_vae_kl_loss: 5.8036\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.7247 - vae_r_loss: 35.8505 - vae_kl_loss: 5.8741 - val_loss: 43.5769 - val_vae_r_loss: 37.8107 - val_vae_kl_loss: 5.7661\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.7198 - vae_r_loss: 35.8361 - vae_kl_loss: 5.8838 - val_loss: 43.5807 - val_vae_r_loss: 37.8855 - val_vae_kl_loss: 5.6952\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.7191 - vae_r_loss: 35.8425 - vae_kl_loss: 5.8766 - val_loss: 43.6381 - val_vae_r_loss: 37.8796 - val_vae_kl_loss: 5.7585\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6607 - vae_r_loss: 35.7753 - vae_kl_loss: 5.8853 - val_loss: 43.5942 - val_vae_r_loss: 37.8272 - val_vae_kl_loss: 5.7670\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6496 - vae_r_loss: 35.7729 - vae_kl_loss: 5.8767 - val_loss: 43.5868 - val_vae_r_loss: 37.6704 - val_vae_kl_loss: 5.9164\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6863 - vae_r_loss: 35.7959 - vae_kl_loss: 5.8904 - val_loss: 43.6931 - val_vae_r_loss: 37.7754 - val_vae_kl_loss: 5.9177\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6309 - vae_r_loss: 35.7477 - vae_kl_loss: 5.8832 - val_loss: 43.7312 - val_vae_r_loss: 37.8486 - val_vae_kl_loss: 5.8826\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 41.6640 - vae_r_loss: 35.7682 - vae_kl_loss: 5.8958 - val_loss: 43.4520 - val_vae_r_loss: 37.5032 - val_vae_kl_loss: 5.9488\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6302 - vae_r_loss: 35.7293 - vae_kl_loss: 5.9009 - val_loss: 43.7112 - val_vae_r_loss: 37.9028 - val_vae_kl_loss: 5.8084\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.6229 - vae_r_loss: 35.7291 - vae_kl_loss: 5.8938 - val_loss: 43.6432 - val_vae_r_loss: 37.7486 - val_vae_kl_loss: 5.8945\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.5947 - vae_r_loss: 35.6854 - vae_kl_loss: 5.9093 - val_loss: 43.6102 - val_vae_r_loss: 37.7369 - val_vae_kl_loss: 5.8733\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 41.5378 - vae_r_loss: 35.6368 - vae_kl_loss: 5.9010 - val_loss: 43.4183 - val_vae_r_loss: 37.5776 - val_vae_kl_loss: 5.8407\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.5435 - vae_r_loss: 35.6271 - vae_kl_loss: 5.9164 - val_loss: 43.7228 - val_vae_r_loss: 37.7464 - val_vae_kl_loss: 5.9764\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.5234 - vae_r_loss: 35.6144 - vae_kl_loss: 5.9090 - val_loss: 43.7529 - val_vae_r_loss: 37.8977 - val_vae_kl_loss: 5.8552\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 41.5304 - vae_r_loss: 35.6144 - vae_kl_loss: 5.9160 - val_loss: 43.7499 - val_vae_r_loss: 37.8566 - val_vae_kl_loss: 5.8934\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.5063 - vae_r_loss: 35.5879 - vae_kl_loss: 5.9184 - val_loss: 43.7301 - val_vae_r_loss: 37.9131 - val_vae_kl_loss: 5.8170\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.4964 - vae_r_loss: 35.5761 - vae_kl_loss: 5.9203 - val_loss: 43.6984 - val_vae_r_loss: 37.8731 - val_vae_kl_loss: 5.8253\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.4689 - vae_r_loss: 35.5399 - vae_kl_loss: 5.9290 - val_loss: 43.4703 - val_vae_r_loss: 37.5691 - val_vae_kl_loss: 5.9012\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 41.4461 - vae_r_loss: 35.5280 - vae_kl_loss: 5.9180 - val_loss: 43.5956 - val_vae_r_loss: 37.5976 - val_vae_kl_loss: 5.9980\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.4367 - vae_r_loss: 35.5115 - vae_kl_loss: 5.9253 - val_loss: 43.6109 - val_vae_r_loss: 37.5420 - val_vae_kl_loss: 6.0688\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.4046 - vae_r_loss: 35.4755 - vae_kl_loss: 5.9291 - val_loss: 43.6073 - val_vae_r_loss: 37.7104 - val_vae_kl_loss: 5.8969\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.4297 - vae_r_loss: 35.4970 - vae_kl_loss: 5.9327 - val_loss: 43.5483 - val_vae_r_loss: 37.6635 - val_vae_kl_loss: 5.8848\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.3969 - vae_r_loss: 35.4541 - vae_kl_loss: 5.9428 - val_loss: 43.5062 - val_vae_r_loss: 37.6395 - val_vae_kl_loss: 5.8667\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.3957 - vae_r_loss: 35.4513 - vae_kl_loss: 5.9444 - val_loss: 43.7233 - val_vae_r_loss: 37.9261 - val_vae_kl_loss: 5.7972\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.3839 - vae_r_loss: 35.4444 - vae_kl_loss: 5.9395 - val_loss: 43.6083 - val_vae_r_loss: 37.6019 - val_vae_kl_loss: 6.0064\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 41.3783 - vae_r_loss: 35.4441 - vae_kl_loss: 5.9342 - val_loss: 43.6412 - val_vae_r_loss: 37.8037 - val_vae_kl_loss: 5.8375\n",
      "\n",
      "Train duration : 391.89 sec. - 0:06:31\n"
     ]
    }
   ],
   "source": [
    "vae.train(x_train,\n",
    "          x_test,\n",
    "          batch_size        = batch_size, \n",
    "          epochs            = epochs,\n",
    "          initial_epoch     = initial_epoch,\n",
    "          k_size            = k_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img width=\"80px\" src=\"../fidle/img/00-Fidle-logo-01.svg\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
