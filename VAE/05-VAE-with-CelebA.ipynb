{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational AutoEncoder (VAE) with CelebA\n",
    "=========================================\n",
    "---\n",
    "Formation Introduction au Deep Learning  (FIDLE) - S. Arias, E. Maldonado, JL. Parouty - CNRS/SARI/DEVLOG - 2020  \n",
    "\n",
    "## Episode 1 - Train a model\n",
    "\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Follow the learning process with Tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Init python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIDLE 2020 - Variational AutoEncoder (VAE)\n",
      "TensorFlow version   : 2.0.0\n",
      "VAE version          : 1.24\n",
      "\n",
      "FIDLE 2020 - Data_generator\n",
      "Version              : 0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, importlib\n",
    "\n",
    "import modules.vae\n",
    "import modules.data_generator\n",
    "\n",
    "importlib.reload(modules.vae)\n",
    "importlib.reload(modules.data_generator)\n",
    "\n",
    "from modules.vae  import VariationalAutoencoder\n",
    "from modules.data_generator import Data_generator\n",
    "\n",
    "VariationalAutoencoder.about()\n",
    "Data_generator.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare data\n",
    "### 2.1 - Dataset localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir  = '/bettik/PROJECTS/pr-fidle/datasets/celeba'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Testing our data generator (Keras Sequence)\n",
    "Just to understand a little bit how our data_generator works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters nb  : 10 files\n",
      "Dataset size : 932\n",
      "Batch size   : 32\n",
      "\n",
      "[shuffle!]\n",
      "\n",
      "[Load 00,s=100] (32) (32) (32) (4..) \n",
      "[Load 01,s=100] (..28) (32) (32) (8..) \n",
      "[Load 02,s=100] (..24) (32) (32) (12..) \n",
      "[Load 03,s=100] (..20) (32) (32) (16..) \n",
      "[Load 04,s=100] (..16) (32) (32) (20..) \n",
      "[Load 05,s=100] (..12) (32) (32) (24..) \n",
      "[Load 06,s= 32] (..8) (24..) \n",
      "[Load 07,s=100] (..8) (32) (32) (28..) \n",
      "[Load 08,s=100] (..4) (32) (32) (32) (0..) \n",
      "[Load 09,s=100] (..32) (32) (32) \n",
      "\n",
      "total number of items : 928\n",
      "batch sizes : [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "# ---- A very small dataset\n",
    "\n",
    "clusters_dir = f'{dataset_dir}/clusters-test'\n",
    "\n",
    "# ---- Instanciate\n",
    "\n",
    "data_gen = Data_generator(clusters_dir,32, debug=True)\n",
    "\n",
    "batch_sizes=[]\n",
    "for i in range( len(data_gen) ):\n",
    "    x,y=data_gen[i]\n",
    "    batch_sizes.append(len(x))\n",
    "\n",
    "print(f'\\n\\ntotal number of items : {sum(batch_sizes)}')\n",
    "print(f'batch sizes : {batch_sizes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Get VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = '001'\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "z_dim       = 2\n",
    "verbose     = 0\n",
    "\n",
    "encoder= [ {'type':'Conv2D',          'filters':32, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'}\n",
    "         ]\n",
    "\n",
    "decoder= [ {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':32, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Conv2DTranspose', 'filters':1,  'kernel_size':(3,3), 'strides':1, 'padding':'same', 'activation':'sigmoid'}\n",
    "         ]\n",
    "\n",
    "vae = modules.vae.VariationalAutoencoder(input_shape    = input_shape, \n",
    "                                         encoder_layers = encoder, \n",
    "                                         decoder_layers = decoder,\n",
    "                                         z_dim          = z_dim, \n",
    "                                         verbose        = verbose,\n",
    "                                         run_tag        = tag)\n",
    "vae.save(model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "r_loss_factor = 1000\n",
    "\n",
    "vae.compile(learning_rate, r_loss_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size        = 100\n",
    "epochs            = 100\n",
    "image_periodicity = 1      # for each epoch\n",
    "chkpt_periodicity = 2      # for each epoch\n",
    "initial_epoch     = 0\n",
    "dataset_size      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.train(x_train,\n",
    "          x_test,\n",
    "          batch_size        = batch_size, \n",
    "          epochs            = epochs,\n",
    "          image_periodicity = image_periodicity,\n",
    "          chkpt_periodicity = chkpt_periodicity,\n",
    "          initial_epoch     = initial_epoch,\n",
    "          dataset_size      = dataset_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
