{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational AutoEncoder (VAE) with CelebA\n",
    "=========================================\n",
    "---\n",
    "Formation Introduction au Deep Learning  (FIDLE) - S. Arias, E. Maldonado, JL. Parouty - CNRS/SARI/DEVLOG - 2020  \n",
    "\n",
    "## Episode 1 - Train a model\n",
    "\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Follow the learning process with Tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Init python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIDLE 2020 - Variational AutoEncoder (VAE)\n",
      "TensorFlow version   : 2.0.0\n",
      "VAE version          : 1.24\n",
      "\n",
      "FIDLE 2020 - DataGenerator\n",
      "Version              : 0.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "from importlib import reload\n",
    "\n",
    "import modules.vae\n",
    "import modules.data_generator\n",
    "\n",
    "reload(modules.data_generator)\n",
    "reload(modules.vae)\n",
    "\n",
    "from modules.vae  import VariationalAutoencoder\n",
    "from modules.data_generator import DataGenerator\n",
    "\n",
    "VariationalAutoencoder.about()\n",
    "DataGenerator.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare data\n",
    "### 2.1 - Dataset localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir  = '/bettik/PROJECTS/pr-fidle/datasets/celeba'\n",
    "\n",
    "train_dir    = f'{dataset_dir}/clusters.train'\n",
    "test_dir     = f'{dataset_dir}/clusters.test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - DataGenerator and validation data\n",
    "Ok, everything's perfect, now let's instantiate our generator for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generator : 6250 batchs of 32 images, or 200000 images\n",
      "x_test : 2599 images\n"
     ]
    }
   ],
   "source": [
    "data_gen = DataGenerator(train_dir, 32, k_size=1)\n",
    "x_test   = np.load(f'{test_dir}/images-000.npy')\n",
    "\n",
    "print(f'Data generator : {len(data_gen)} batchs of {data_gen.batch_size} images, or {data_gen.dataset_size} images')\n",
    "print(f'x_test : {len(x_test)} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Get VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "Outputs will be in  : ./run/CelebA.001\n",
      "Config saved in     : ./run/CelebA.001/models/vae_config.json\n"
     ]
    }
   ],
   "source": [
    "tag = 'CelebA.001'\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "z_dim       = 200\n",
    "verbose     = 0\n",
    "\n",
    "encoder= [ {'type':'Conv2D',          'filters':32, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2D',          'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "         ]\n",
    "\n",
    "decoder= [ {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2DTranspose', 'filters':64, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2DTranspose', 'filters':32, 'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'relu'},\n",
    "           {'type':'Dropout',         'rate':0.25},\n",
    "           {'type':'Conv2DTranspose', 'filters':3,  'kernel_size':(3,3), 'strides':2, 'padding':'same', 'activation':'sigmoid'}\n",
    "         ]\n",
    "\n",
    "vae = modules.vae.VariationalAutoencoder(input_shape    = input_shape, \n",
    "                                         encoder_layers = encoder, \n",
    "                                         decoder_layers = decoder,\n",
    "                                         z_dim          = z_dim, \n",
    "                                         verbose        = verbose,\n",
    "                                         run_tag        = tag)\n",
    "vae.save(model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled.\n",
      "Optimizer is Adam with learning_rate=0.005\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "r_loss_factor = 10000\n",
    "\n",
    "vae.compile(learning_rate, r_loss_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs            = 6\n",
    "image_periodicity = 8      # for each epoch\n",
    "chkpt_periodicity = 1      # for each epoch\n",
    "initial_epoch     = 0\n",
    "dataset_size      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "6250/6250 [==============================] - 206s 33ms/step - loss: 338.2761 - vae_r_loss: 298.7408 - vae_kl_loss: 39.5353 - val_loss: 309.0752 - val_vae_r_loss: 276.8837 - val_vae_kl_loss: 31.9974\n",
      "Epoch 2/6\n",
      "6250/6250 [==============================] - 209s 33ms/step - loss: 296.6832 - vae_r_loss: 256.9755 - vae_kl_loss: 39.7077 - val_loss: 289.8210 - val_vae_r_loss: 255.9433 - val_vae_kl_loss: 33.6266\n",
      "Epoch 3/6\n",
      "6250/6250 [==============================] - 200s 32ms/step - loss: 293.1235 - vae_r_loss: 253.5661 - vae_kl_loss: 39.5573 - val_loss: 302.0345 - val_vae_r_loss: 268.0425 - val_vae_kl_loss: 33.7719\n",
      "Epoch 4/6\n",
      "6250/6250 [==============================] - 205s 33ms/step - loss: 292.2448 - vae_r_loss: 252.9195 - vae_kl_loss: 39.3251 - val_loss: 273.3243 - val_vae_r_loss: 239.4294 - val_vae_kl_loss: 33.6550\n",
      "Epoch 5/6\n",
      "6250/6250 [==============================] - 216s 35ms/step - loss: 292.4938 - vae_r_loss: 253.2241 - vae_kl_loss: 39.2703 - val_loss: 277.4104 - val_vae_r_loss: 242.7441 - val_vae_kl_loss: 34.3019\n",
      "Epoch 6/6\n",
      "6250/6250 [==============================] - 215s 34ms/step - loss: 293.1409 - vae_r_loss: 253.9680 - vae_kl_loss: 39.1729 - val_loss: 294.6553 - val_vae_r_loss: 260.5944 - val_vae_kl_loss: 33.8707\n",
      "\n",
      "Train duration : 1251.56 sec. - 0:20:51\n"
     ]
    }
   ],
   "source": [
    "vae.train(#x_train     = x_train,\n",
    "          data_generator    = data_gen,\n",
    "          x_test            = x_test,\n",
    "          epochs            = epochs,\n",
    "          image_periodicity = image_periodicity,\n",
    "          chkpt_periodicity = chkpt_periodicity,\n",
    "          initial_epoch     = initial_epoch\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
