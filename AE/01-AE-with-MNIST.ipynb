{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"../fidle/img/00-Fidle-header-01.svg\"></img>\n",
    "\n",
    "# <!-- TITLE --> [AE1] - Building and training an AE denoiser model\n",
    "<!-- DESC --> Episode 1 : After construction, the model is trained with noisy data from the MNIST dataset.\n",
    "\n",
    "<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n",
    "\n",
    "## Objectives :\n",
    " - Understanding and implementing a denoizing **autoencoder** neurals network (AE)\n",
    " - Understanding a more **advanced programming model**\n",
    "\n",
    "The calculation needs being important, it is preferable to use a very simple dataset such as MNIST.  \n",
    "The use of a GPU is often indispensable.\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Follow the learning process with Tensorboard\n",
    "\n",
    "Thanks to **Fran√ßois Chollet** whose VAE example has greatly inspired this example.  \n",
    "See : https://keras.io/examples/generative/vae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Init python stuff\n",
    "### 1.1 - Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from modules.callbacks          import ImagesCallback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "import os,sys,json,time,datetime\n",
    "from importlib import reload\n",
    "from IPython.display import display,Image,Markdown,HTML\n",
    "import h5py\n",
    "\n",
    "from skimage import io\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import modules.AE\n",
    "from modules.AE           import AE\n",
    "from modules.loader_MNIST import Loader_MNIST\n",
    "from modules.callbacks    import ImagesCallback, BestModelCallback\n",
    "\n",
    "sys.path.append('..')\n",
    "import fidle.pwk as pwk\n",
    "\n",
    "datasets_dir = pwk.init('AE1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Parameters\n",
    "`output_dir` : Place to save prepared dataset (need 420 Mo)  \n",
    "`output_filename` : Filename of the prepared dataset  \n",
    "`scale` : % of the dataset to use (1. for 100%)  \n",
    "`latent_dim` : Dimension of the latent space  \n",
    "`batch_size` : Batch size  \n",
    "`epochs` : Nb of epochs for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir      = './data'\n",
    "output_filename = 'mnist-noisy.h5'\n",
    "\n",
    "scale           = .1\n",
    "\n",
    "latent_dim      = 10\n",
    "\n",
    "batch_size      = 128\n",
    "epochs          = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare dataset\n",
    "### 2.1 - Get MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = Loader_MNIST.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Add noise\n",
    "We will add noise to our input dataset (x_data)  \n",
    "Our goal is to predict noiselessly data (y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_it(x_data, about):\n",
    "    for i,image in enumerate(x_data):\n",
    "        pwk.update_progress(about,i+1,len(x_data))\n",
    "        image=random_noise(image, mode='gaussian', mean=0, var=0.3)\n",
    "        image=random_noise(image, mode='s&p',      amount=0.2, salt_vs_pepper=0.5)\n",
    "        image=random_noise(image, mode='poisson') \n",
    "        image=random_noise(image, mode='speckle',  mean=0, var=0.1)\n",
    "        x_data[i]=image\n",
    "    print('Done.')\n",
    "    return x_data\n",
    "\n",
    "\n",
    "# ---- What we want to predict\n",
    "#\n",
    "y_data = np.copy(x_data)\n",
    "\n",
    "# ---- Add noise to input data\n",
    "#\n",
    "x_data = noise_it(x_data, 'Add noise to x_train :')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Noisy dataset (x_data) : ',x_data.shape)\n",
    "print('Clean dataset (y_data) : ',y_data.shape)\n",
    "\n",
    "pwk.subtitle('Noisy images (input data or x)')\n",
    "pwk.plot_images(x_data[:5], None, indices='all', columns=5, x_size=3,y_size=3, interpolation=None, save_as='01-noisy')\n",
    "pwk.subtitle('Original images we want to obtain (output data or y)')\n",
    "pwk.plot_images(y_data[:5], None, indices='all', columns=5, x_size=3,y_size=3, interpolation=None, save_as='02-original')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Shuffle and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(x_data))\n",
    "x_data, y_data = x_data[p], y_data[p]\n",
    "x_train, y_train = x_data[:60000], y_data[:60000]\n",
    "x_test,  y_test  = x_data[60000:], y_data[60000:]\n",
    "\n",
    "print(f'x_train:{x_train.shape}  y_train:{y_train.shape}')\n",
    "print(f'x_test :{x_test.shape}  y_test :{y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Save prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwk.mkdir(output_dir)\n",
    "\n",
    "with h5py.File(f'{output_dir}/{output_filename}', \"w\") as f:\n",
    "    f.create_dataset(\"x_train\", data=x_train)\n",
    "    f.create_dataset(\"y_train\", data=y_train)\n",
    "    f.create_dataset(\"x_test\",  data=x_test)\n",
    "    f.create_dataset(\"y_test\",  data=y_test)\n",
    "    print('Saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(modules.AE)\n",
    "from modules.AE          import AE\n",
    "\n",
    "inputs    = keras.Input(shape=(28, 28, 1))\n",
    "x         = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(inputs)\n",
    "x         = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x         = layers.Flatten()(x)\n",
    "x         = layers.Dense(16, activation=\"relu\")(x)\n",
    "z         = layers.Dense(latent_dim)(x)\n",
    "\n",
    "encoder = keras.Model(inputs, z, name=\"encoder\")\n",
    "encoder.compile()\n",
    "# encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = keras.Input(shape=(latent_dim,))\n",
    "x       = layers.Dense(7 * 7 * 64, activation=\"relu\")(inputs)\n",
    "x       = layers.Reshape((7, 7, 64))(x)\n",
    "x       = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x       = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "decoder = keras.Model(inputs, outputs, name=\"decoder\")\n",
    "decoder.compile()\n",
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AE(encoder, decoder)\n",
    "\n",
    "ae.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Train\n",
    "20' on a CPU  \n",
    "1'12 on a GPU (V100, IDRIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Callback : Images\n",
    "#\n",
    "pwk.mkdir('./run/images')\n",
    "filename = './run/images/image-{epoch:03d}-{i:02d}.jpg'\n",
    "callback_images = ImagesCallback(filename, x=x_test[:5], encoder=encoder,decoder=decoder)\n",
    "\n",
    "# ---- Callback : Best model\n",
    "#\n",
    "pwk.mkdir('./run/models')\n",
    "filename = './run/models/best_model'\n",
    "callback_bestmodel = BestModelCallback(filename)\n",
    "\n",
    "# ---- Callback tensorboard\n",
    "#\n",
    "dirname = './run/logs'\n",
    "callback_tensorboard = TensorBoard(log_dir=dirname, histogram_freq=1)\n",
    "\n",
    "# callbacks_list = [callback_images, callback_bestmodel, callback_tensorboard]\n",
    "callbacks_list = [callback_images, callback_bestmodel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwk.chrono_start()\n",
    "\n",
    "n=int(scale*len(x_train))\n",
    "print(f'Train set size is : {n}\\n')\n",
    "\n",
    "history = ae.fit(x_train[:n],y_train[:n], epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
    "\n",
    "pwk.chrono_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwk.plot_history(history,  plot={\"Loss\":['loss']}, save_as='03-history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Learning progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[]\n",
    "labels=[]\n",
    "for epoch in range(epochs):\n",
    "    for i in range(5):\n",
    "        filename = './run/images/image-{epoch:03d}-{i:02d}.jpg'.format(epoch=epoch, i=i)\n",
    "        img      = io.imread(filename)\n",
    "        imgs.append(img)\n",
    "        \n",
    "\n",
    "pwk.subtitle('Real images :')\n",
    "pwk.plot_images(y_test[:5], None, indices='all', columns=5, x_size=2,y_size=2, interpolation=None, save_as='04-original-real')\n",
    "\n",
    "pwk.subtitle('Noisy images :')\n",
    "pwk.plot_images(x_test[:5], None, indices='all', columns=5, x_size=2,y_size=2, interpolation=None, save_as='05-original-noisy')\n",
    "\n",
    "pwk.subtitle('Learning...')\n",
    "pwk.plot_images(imgs, None, indices='all', columns=5, x_size=2,y_size=2, interpolation=None, save_as='06-learning')\n",
    "\n",
    "pwk.subtitle('Noisy images :')\n",
    "pwk.plot_images(x_test[:5], None, indices='all', columns=5, x_size=2,y_size=2, interpolation=None, save_as=None)\n",
    "\n",
    "pwk.subtitle('Real images :')\n",
    "pwk.plot_images(y_test[:5], None, indices='all', columns=5, x_size=2,y_size=2, interpolation=None, save_as=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwk.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img width=\"80px\" src=\"../fidle/img/00-Fidle-logo-01.svg\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
