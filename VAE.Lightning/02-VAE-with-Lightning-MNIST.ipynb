{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"../fidle/img/header.svg\"></img>\n",
    "\n",
    "# <!-- TITLE --> [LVAE2] - VAE, using a custom model class  (MNIST dataset)\n",
    "<!-- DESC --> Construction and training of a VAE, using model subclass, with a latent space of small dimension, using PyTorch Lightninh\n",
    "\n",
    "<!-- AUTHOR : Achille Mbogol Touye (EFILIA-MIAI/SIMaP) -->\n",
    "\n",
    "## Objectives :\n",
    " - Understanding and implementing a **variational autoencoder** neurals network (VAE)\n",
    " - Understanding a still more **advanced programming model**, using a **custom model**\n",
    "\n",
    "The calculation needs being important, it is preferable to use a very simple dataset such as MNIST to start with.  \n",
    "...MNIST with a small scale if you haven't a GPU ;-)\n",
    "\n",
    "## What we're going to do :\n",
    "\n",
    " - Defining a VAE model\n",
    " - Build the model\n",
    " - Train it\n",
    " - Have a look on the train process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Init python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torch.utils.data    import TensorDataset, DataLoader\n",
    "from modules.callbacks   import ImagesCallback,BestModelCallback\n",
    "from modules.progressbar import CustomTrainProgressBar\n",
    "from modules.layers      import SamplingLayer\n",
    "from modules.datagen     import MNIST\n",
    "from modules.models      import VAE, Encoder, Decoder\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import fidle\n",
    "\n",
    "# Init Fidle environment\n",
    "run_id, run_dir, datasets_dir = fidle.init('LVAE2')\n",
    "\n",
    "VAE.about()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Parameters\n",
    "`scale` : with scale=1, we need 1'30s on a GPU V100 ...and >20' on a CPU !  \n",
    "`latent_dim` : 2 dimensions is small, but usefull to draw !  \n",
    "`fit_verbosity`: Verbosity of training progress bar: 0=silent, 1=progress bar, 2=One line  \n",
    "\n",
    "`loss_weights` : Our **loss function** is the weighted sum of two loss:\n",
    " - `r_loss` which measures the loss during reconstruction.  \n",
    " - `kl_loss` which measures the dispersion.  \n",
    "\n",
    "The weights are defined by: `loss_weights=[k1,k2]` where : `total_loss = k1*r_loss + k2*kl_loss`  \n",
    "In practice, a value of \\[1,.01\\] gives good results here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim    = 6\n",
    "loss_weights  = [1,.001]       # [1, .001] give good results\n",
    "\n",
    "scale         = .2\n",
    "seed          = 123\n",
    "\n",
    "batch_size    = 64\n",
    "epochs        = 5\n",
    "fit_verbosity = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override parameters (batch mode) - Just forget this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidle.override('latent_dim', 'loss_weights', 'scale', 'seed', 'batch_size', 'epochs', 'fit_verbosity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Prepare data\n",
    "`MNIST.get_data()` return : `x_train,y_train, x_test,y_test`,  \\\n",
    "but we only need x_train for our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data, _,_ = MNIST.get_data(seed=seed, scale=scale, train_prop=1 )\n",
    "\n",
    "fidle.scrawler.images(x_data[:20], None, indices='all', columns=10, x_size=1,y_size=1,y_padding=0, save_as='01-original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.1 -  For Training model use Dataloader\n",
    "The Dataset retrieves our datasetâ€™s features and labels one sample at a time. While training a model, we typically want to pass samples in minibatches, reshuffle the data at every epoch to reduce model overfitting. DataLoader is an iterable that abstracts this complexity for us in an easy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_data,y_data)\n",
    "\n",
    "# train bacth data\n",
    "train_loader= DataLoader(\n",
    "  dataset=train_dataset, \n",
    "  shuffle=False, \n",
    "  batch_size=batch_size, \n",
    "  num_workers=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Build model\n",
    "In this example, we will use a **custom model**.\n",
    "For this, we will use :\n",
    " - `SamplingLayer`, which generates a vector z from the parameters z_mean and z_logvar - See : [SamplingLayer.py](./modules/layers/SamplingLayer.py)\n",
    " - `VAE`, a custom model- See : [VAE.py](./modules/models/VAE.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE\n",
    "`VAE` is a custom model with a specific train_step - See : [VAE.py](./modules/models/VAE.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae=VAE(Encoder(latent_dim = latent_dim),\n",
    "        Decoder(latent_dim = latent_dim),\n",
    "        loss_weights\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train\n",
    "### 5.1 - Using two nice custom callbacks :-)\n",
    "Two custom callbacks are used:\n",
    " - `ImagesCallback` : qui va sauvegarder des images durant l'apprentissage - See [ImagesCallback.py](./modules/callbacks/ImagesCallback.py)\n",
    " - `BestModelCallback` : qui sauvegardera le meilleur model - See [BestModelCallback.py](./modules/callbacks/BestModelCallback.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./run/models_dir/\"\n",
    "BestModelCallback   = BestModelCallback(dirpath = save_dir)\n",
    "CallbackImages      = ImagesCallback(x=x_data, z_dim=latent_dim, nb_images=5, from_z=True, from_random=True, run_dir=run_dir)\n",
    "logger              = TensorBoardLogger(save_dir='VAE2_logs',name=\"VAE_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Let's train !\n",
    "With `scale=1`, need 1'15 on a GPU (V100 at IDRIS) ...or 20' on a CPU  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrono=fidle.Chrono()\n",
    "chrono.start()\n",
    "\n",
    "# train model\n",
    "trainer= pl.Trainer(accelerator='auto',\n",
    "                    max_epochs=epochs,\n",
    "                    logger=logger,\n",
    "                    num_sanity_val_steps=0,\n",
    "                   callbacks=[CustomTrainProgressBar(), BestModelCallback, CallbackImages]\n",
    "                   )\n",
    "\n",
    "trainer.fit(model=vae, train_dataloaders=train_loader)\n",
    "\n",
    "\n",
    "\n",
    "chrono.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Training review\n",
    "### 6.1 - History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch Tensorboard \n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./VAE1_logs/VAE_logs/ --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Reconstruction during training\n",
    "At the end of each epoch, our callback saved some reconstructed images.  \n",
    "Where :  \n",
    "Original image -> encoder -> z -> decoder -> Reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_z, images_r = CallbackImages.get_images( range(0,epochs,2) )\n",
    "\n",
    "fidle.utils.subtitle('Original images :')\n",
    "fidle.scrawler.images(x_data[:5], None, indices='all', columns=5, x_size=2,y_size=2, save_as='02-original')\n",
    "\n",
    "fidle.utils.subtitle('Encoded/decoded images')\n",
    "fidle.scrawler.images(images_z, None, indices='all', columns=5, x_size=2,y_size=2, save_as='03-reconstruct')\n",
    "\n",
    "fidle.utils.subtitle('Original images :')\n",
    "fidle.scrawler.images(x_data[:5], None, indices='all', columns=5, x_size=2,y_size=2, save_as=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 - Generation (latent -> decoder) during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidle.utils.subtitle('Generated images from latent space')\n",
    "fidle.scrawler.images(images_r, None, indices='all', columns=5, x_size=2,y_size=2, save_as='04-encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Reload best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestModelCallback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Load the model from a checkpoint\n",
    "vae = VAE.load_from_checkpoint(BestModelCallback.best_model_path,\n",
    "                                encoder=Encoder(latent_dim=latent_dim),\n",
    "                                decoder=Decoder(latent_dim=latent_dim)\n",
    "                              )\n",
    "# put model in evaluation mode\n",
    "vae.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Select few images\n",
    "\n",
    "x_show = fidle.utils.pick_dataset(x_data, n=10)\n",
    "\n",
    "# ---- Get latent points and reconstructed images\n",
    "\n",
    "z_mean, z_var, z  = vae.encoder(x_show.to(device))\n",
    "x_reconst         = vae.decoder(z)\n",
    "\n",
    "# ---- Show it\n",
    "z         = z.cpu().detach()\n",
    "x_reconst = x_reconst.cpu().detach()\n",
    "\n",
    "labels=[ str(np.round(z[i],1)) for i in range(10) ]\n",
    "\n",
    "fidle.scrawler.images(x_show,    None, indices='all', columns=10, x_size=2,y_size=2, save_as='05-original')\n",
    "fidle.scrawler.images(x_reconst, None, indices='all', columns=10, x_size=2,y_size=2, save_as='06-reconstruct')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - Visualization of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_show = int(20000*scale)\n",
    "\n",
    "# ---- Select images\n",
    "\n",
    "x_show, y_show = fidle.utils.pick_dataset(x_data,y_data, n=n_show)\n",
    "\n",
    "# ---- Get latent points\n",
    "\n",
    "z_mean, z_var, z = vae.encoder(x_show.to(device))\n",
    "\n",
    "# ---- Show them\n",
    "z         = z.cpu().detach()           # Move the tensor to CPU and detach it\n",
    "x_reconst = x_reconst.cpu().detach()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "plt.scatter(z[:, 0] , z[:, 1], c=y_show, cmap= 'tab10', alpha=0.5, s=30)\n",
    "plt.colorbar()\n",
    "fidle.scrawler.save_fig('07-Latent-space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 - Generative latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latent_dim>2:\n",
    "\n",
    "    print('Sorry, This part can only work if the latent space is of dimension 2')\n",
    "\n",
    "else:\n",
    "    \n",
    "    grid_size   = 18\n",
    "    grid_scale  = 1\n",
    "\n",
    "    # ---- Draw a ppf grid\n",
    "\n",
    "    grid=[]\n",
    "    for y in scipy.stats.norm.ppf(np.linspace(0.99, 0.01, grid_size),scale=grid_scale):\n",
    "        for x in scipy.stats.norm.ppf(np.linspace(0.01, 0.99, grid_size),scale=grid_scale):\n",
    "            grid.append( (x,y) )\n",
    "    grid=np.array(grid)\n",
    "\n",
    "    # ---- Draw latentspoints and grid\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(z[:, 0] , z[:, 1], c=y_show, cmap= 'tab10', alpha=0.5, s=20)\n",
    "    plt.scatter(grid[:, 0] , grid[:, 1], c = 'black', s=60, linewidth=2, marker='+', alpha=1)\n",
    "    fidle.scrawler.save_fig('08-Latent-grid')\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Plot grid corresponding images\n",
    "    grid=torch.from_numpy(grid).to(device)\n",
    "    x_reconst = vae.decoder([grid])\n",
    "    x_reconst = x_reconst.cpu().detach()\n",
    "    fidle.scrawler.images(x_reconst, indices='all', columns=grid_size, x_size=0.5,y_size=0.5, y_padding=0,spines_alpha=0.1, save_as='09-Latent-morphing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidle.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img width=\"80px\" src=\"../fidle/img/logo-paysage.svg\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3929042cc22c1274d74e3e946c52b845b57cb6d84f2d591ffe0519b38e4896d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
