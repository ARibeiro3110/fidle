{
    "LINR1": {
        "id": "LINR1",
        "dirname": "LinearReg",
        "basename": "01-Linear-Regression.ipynb",
        "title": "Linear regression with direct resolution",
        "description": "Direct determination of linear regression "
    },
    "GRAD1": {
        "id": "GRAD1",
        "dirname": "LinearReg",
        "basename": "02-Gradient-descent.ipynb",
        "title": "Linear regression with gradient descent",
        "description": "An example of gradient descent in the simple case of a linear regression."
    },
    "POLR1": {
        "id": "POLR1",
        "dirname": "LinearReg",
        "basename": "03-Polynomial-Regression.ipynb",
        "title": "Complexity Syndrome",
        "description": "Illustration of the problem of complexity with the polynomial regression"
    },
    "LOGR1": {
        "id": "LOGR1",
        "dirname": "LinearReg",
        "basename": "04-Logistic-Regression.ipynb",
        "title": "Logistic regression, with sklearn",
        "description": "Logistic Regression using Sklearn"
    },
    "PER57": {
        "id": "PER57",
        "dirname": "IRIS",
        "basename": "01-Simple-Perceptron.ipynb",
        "title": "Perceptron Model 1957",
        "description": "A simple perceptron, with the IRIS dataset."
    },
    "MNIST1": {
        "id": "MNIST1",
        "dirname": "MNIST",
        "basename": "01-DNN-MNIST.ipynb",
        "title": "Simple classification with DNN",
        "description": "Example of classification with a fully connected neural network"
    },
    "GTSRB1": {
        "id": "GTSRB1",
        "dirname": "GTSRB",
        "basename": "01-Preparation-of-data.ipynb",
        "title": "CNN with GTSRB dataset - Data analysis and preparation",
        "description": "Episode 1 : Data analysis and creation of a usable dataset"
    },
    "GTSRB2": {
        "id": "GTSRB2",
        "dirname": "GTSRB",
        "basename": "02-First-convolutions.ipynb",
        "title": "CNN with GTSRB dataset - First convolutions",
        "description": "Episode 2 : First convolutions and first results"
    },
    "GTSRB3": {
        "id": "GTSRB3",
        "dirname": "GTSRB",
        "basename": "03-Tracking-and-visualizing.ipynb",
        "title": "CNN with GTSRB dataset - Monitoring ",
        "description": "Episode 3 : Monitoring and analysing training, managing checkpoints"
    },
    "GTSRB4": {
        "id": "GTSRB4",
        "dirname": "GTSRB",
        "basename": "04-Data-augmentation.ipynb",
        "title": "CNN with GTSRB dataset - Data augmentation ",
        "description": "Episode 4 : Improving the results with data augmentation"
    },
    "GTSRB5": {
        "id": "GTSRB5",
        "dirname": "GTSRB",
        "basename": "05-Full-convolutions.ipynb",
        "title": "CNN with GTSRB dataset - Full convolutions ",
        "description": "Episode 5 : A lot of models, a lot of datasets and a lot of results."
    },
    "GTSRB6": {
        "id": "GTSRB6",
        "dirname": "GTSRB",
        "basename": "06-Notebook-as-a-batch.ipynb",
        "title": "Full convolutions as a batch",
        "description": "Episode 6 : Run Full convolution notebook as a batch"
    },
    "GTSRB7": {
        "id": "GTSRB7",
        "dirname": "GTSRB",
        "basename": "07-Show-report.ipynb",
        "title": "CNN with GTSRB dataset - Show reports",
        "description": "Episode 7 : Displaying a jobs report"
    },
    "GTSRB10": {
        "id": "GTSRB10",
        "dirname": "GTSRB",
        "basename": "batch_oar.sh",
        "title": "OAR batch submission",
        "description": "Bash script for OAR batch submission of GTSRB notebook "
    },
    "GTSRB11": {
        "id": "GTSRB11",
        "dirname": "GTSRB",
        "basename": "batch_slurm.sh",
        "title": "SLURM batch script",
        "description": "Bash script for SLURM batch submission of GTSRB notebooks "
    },
    "IMDB1": {
        "id": "IMDB1",
        "dirname": "IMDB",
        "basename": "01-Embedding-Keras.ipynb",
        "title": "Text embedding with IMDB",
        "description": "A very classical example of word embedding for text classification (sentiment analysis)"
    },
    "IMDB2": {
        "id": "IMDB2",
        "dirname": "IMDB",
        "basename": "02-Prediction.ipynb",
        "title": "Text embedding with IMDB - Reloaded",
        "description": "Example of reusing a previously saved model"
    },
    "IMDB3": {
        "id": "IMDB3",
        "dirname": "IMDB",
        "basename": "03-LSTM-Keras.ipynb",
        "title": "Text embedding/LSTM model with IMDB",
        "description": "Still the same problem, but with a network combining embedding and LSTM"
    },
    "SYNOP1": {
        "id": "SYNOP1",
        "dirname": "SYNOP",
        "basename": "01-Preparation-of-data.ipynb",
        "title": "Time series with RNN - Preparation of data",
        "description": "Episode 1 : Data analysis and creation of a usable dataset"
    },
    "SYNOP2": {
        "id": "SYNOP2",
        "dirname": "SYNOP",
        "basename": "02-First-predictions.ipynb",
        "title": "Time series with RNN - Try a prediction",
        "description": "Episode 2 : Training session and first predictions"
    },
    "SYNOP3": {
        "id": "SYNOP3",
        "dirname": "SYNOP",
        "basename": "03-12h-predictions.ipynb",
        "title": "Time series with RNN - 12h predictions",
        "description": "Episode 3: Attempt to predict in the longer term "
    },
    "VAE1": {
        "id": "VAE1",
        "dirname": "VAE",
        "basename": "01-VAE-with-MNIST.ipynb",
        "title": "Variational AutoEncoder (VAE) with MNIST",
        "description": "Building a simple model with the MNIST dataset"
    },
    "VAE2": {
        "id": "VAE2",
        "dirname": "VAE",
        "basename": "02-VAE-with-MNIST-post.ipynb",
        "title": "Variational AutoEncoder (VAE) with MNIST - Analysis",
        "description": "Visualization and analysis of latent space"
    },
    "VAE3": {
        "id": "VAE3",
        "dirname": "VAE",
        "basename": "05-About-CelebA.ipynb",
        "title": "About the CelebA dataset",
        "description": "Presentation of the CelebA dataset and problems related to its size"
    },
    "VAE6": {
        "id": "VAE6",
        "dirname": "VAE",
        "basename": "06-Prepare-CelebA-datasets.ipynb",
        "title": "Preparation of the CelebA dataset",
        "description": "Preparation of a clustered dataset, batchable"
    },
    "VAE7": {
        "id": "VAE7",
        "dirname": "VAE",
        "basename": "07-Check-CelebA.ipynb",
        "title": "Checking the clustered CelebA dataset",
        "description": "Check the clustered dataset"
    },
    "VAE8": {
        "id": "VAE8",
        "dirname": "VAE",
        "basename": "08-VAE-with-CelebA.ipynb",
        "title": "Variational AutoEncoder (VAE) with CelebA",
        "description": "Building a VAE and train it, using a data generator"
    },
    "VAE9": {
        "id": "VAE9",
        "dirname": "VAE",
        "basename": "09-VAE-withCelebA-post.ipynb",
        "title": "Variational AutoEncoder (VAE) with CelebA - Analysis",
        "description": "Exploring latent space of our trained models"
    },
    "VAE10": {
        "id": "VAE10",
        "dirname": "VAE",
        "basename": "batch_slurm.sh",
        "title": "SLURM batch script",
        "description": "Bash script for SLURM batch submission of VAE notebooks "
    },
    "ACTF1": {
        "id": "ACTF1",
        "dirname": "Misc",
        "basename": "Activation-Functions.ipynb",
        "title": "Activation functions",
        "description": "Some activation functions, with their derivatives."
    },
    "NP1": {
        "id": "NP1",
        "dirname": "Misc",
        "basename": "Numpy.ipynb",
        "title": "A short introduction to Numpy",
        "description": "Numpy is an essential tool for the Scientific Python."
    },
    "TSB1": {
        "id": "TSB1",
        "dirname": "Misc",
        "basename": "Using-Tensorboard.ipynb",
        "title": "Tensorboard with/from Jupyter ",
        "description": "4 ways to use Tensorboard from the Jupyter environment"
    }
}