campain:
  version:           1.0
  description:       Full validation of notebooks with scale parameters set to 1
  directory:         ./campains/scale1_settings
  existing_notebook: skip
  report_template:   fidle
  timeout:           6000
  environment_vars:
    FIDLE_SAVE_FIGS:         true
    TF_CPP_MIN_LOG_LEVEL:    2


#
# ------------ LinearReg
#
LINR1:
  notebook: LinearReg/01-Linear-Regression.ipynb

GRAD1:
  notebook: LinearReg/02-Gradient-descent.ipynb

POLR1:
  notebook: LinearReg/03-Polynomial-Regression.ipynb

LOGR1:
  notebook: LinearReg/04-Logistic-Regression.ipynb

#
# ------------ IRIS
#
PER57:
  notebook: IRIS/01-Simple-Perceptron.ipynb

#
# ------------ BHPD
#
BHPD1:
  notebook: BHPD/01-DNN-Regression.ipynb
  overrides:
    fit_verbosity: 2

BHPD2:
  notebook: BHPD/02-DNN-Regression-Premium.ipynb
  overrides:
    fit_verbosity: 2

WINE1.1:
  notebook: BHPD/03-DNN-Wine-Regression.ipynb
  overrides:
    fit_verbosity: 2
    dataset_name: winequality-red.csv

WINE1.2:
  notebook: BHPD/03-DNN-Wine-Regression.ipynb
  overrides:
    fit_verbosity: 2
    dataset_name: winequality-red.csv

#
# ------------ MNIST
#
MNIST1:
  notebook: MNIST/01-DNN-MNIST.ipynb
  overrides:
    fit_verbosity: 2

MNIST2:
  notebook: MNIST/02-CNN-MNIST.ipynb
  overrides:
    fit_verbosity: 2

#
# ------------ GTSRB
#
GTSRB1:
  notebook:      GTSRB/01-Preparation-of-data.ipynb
  overrides:
    scale:                 .05
    output_dir:            ./data
    progress_verbosity:    2

GTSRB2:
  notebook:      GTSRB/02-First-convolutions.ipynb
  after:         GTSRB1
  overrides:
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    dataset_name:          set-24x24-L
    batch_size:            64
    epochs:                5
    scale:                 1
    fit_verbosity:         2

GTSRB3:
  notebook:      GTSRB/03-Tracking-and-visualizing.ipynb
  after:         GTSRB1
  overrides:
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    dataset_name:          set-24x24-L
    batch_size:            64
    epochs:                5
    scale:                 1
    fit_verbosity:         2

GTSRB4:
  notebook:      GTSRB/04-Data-augmentation.ipynb
  after:         GTSRB1
  overrides:
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    dataset_name:          set-24x24-L
    batch_size:            64
    epochs:                5
    scale:                 1
    fit_verbosity:         2

GTSRB5_1:
  notebook:      GTSRB/05-Full-convolutions.ipynb
  after:         GTSRB1
  overrides:
    run_dir:               ./run/GTSRB5
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    datasets:              "['set-24x24-L', 'set-24x24-RGB', 'set-48x48-L', 'set-48x48-RGB', 'set-24x24-L-LHE', 'set-24x24-RGB-HE', 'set-48x48-L-LHE', 'set-48x48-RGB-HE']"
    models:                "{'v1':'get_model_v1', 'v2':'get_model_v2', 'v3':'get_model_v3'}"
    batch_size:            64
    epochs:                16
    scale:                 1
    with_datagen:          False
    fit_verbosity:         2

GTSRB5_2:
  notebook:      GTSRB/05-Full-convolutions.ipynb
  after:         GTSRB1
  overrides:
    run_dir:               ./run/GTSRB5
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    datasets:              "['set-24x24-L', 'set-24x24-RGB', 'set-48x48-L', 'set-48x48-RGB', 'set-24x24-L-LHE', 'set-24x24-RGB-HE', 'set-48x48-L-LHE', 'set-48x48-RGB-HE']"
    models:                "{'v1':'get_model_v1', 'v2':'get_model_v2', 'v3':'get_model_v3'}"
    batch_size:            64
    epochs:                16
    scale:                 1
    with_datagen:          False
    fit_verbosity:         2

GTSRB5_3:
  notebook:      GTSRB/05-Full-convolutions.ipynb
  after:         GTSRB1
  overrides:
    run_dir:               ./run/GTSRB5
    enhanced_dir:          '{datasets_dir}/GTSRB/enhanced'
    datasets:              "['set-48x48-L', 'set-48x48-RGB']"
    models:                "{'v2':'get_model_v2', 'v3':'get_model_v3'}"
    batch_size:            64
    epochs:                16
    scale:                 1
    with_datagen:          True
    fit_verbosity:         2

GTSRB6:
  notebook:      GTSRB/06-Notebook-as-a-batch.ipynb

GTSRB7:
  notebook:      GTSRB/07-Show-report.ipynb
  after:         GTSRB5
  overrides:
    report_dir:            ./run/GTSRB5

#
# ------------ IMDB
#
IMDB1:
  notebook:      IMDB/01-One-hot-encoding.ipynb
  overrides:
    vocab_size:            8000
    hide_most_frequently:  0
    batch_size:            512
    epochs:                10
    fit_verbosity:         2

IMDB2:
  notebook:      IMDB/02-Keras-embedding.ipynb
  overrides:
    vocab_size:            8000
    hide_most_frequently:  0
    review_len:            256
    dense_vector_size:     32
    batch_size:            512
    epochs:                30
    output_dir:            default
    fit_verbosity:         2

IMDB3:
  notebook:      IMDB/03-Prediction.ipynb
  after:         IMDB2
  overrides:
    vocab_size:            8000
    review_len:            256
    saved_models:          default
    dictionaries_dir:      default

IMDB4:
  notebook:      IMDB/04-Show-vectors.ipynb
  after:         IMDB2
  overrides:
    vocab_size:            8000
    review_len:            256
    saved_models:          default
    dictionaries_dir:      default

IMDB5:
  notebook:      IMDB/05-LSTM-Keras.ipynb
  overrides:
    vocab_size:            8000
    hide_most_frequently:  0
    review_len:            256
    dense_vector_size:     32
    batch_size:            512
    epochs:                10
    scale:                 1
    fit_verbosity:         2

#
# ------------ SYNOP
#
LADYB1:
  notebook:      SYNOP/LADYB1-Ladybug.ipynb
  overrides:
    scale:                 1
    train_prop:            0.8
    sequence_len:          20
    predict_len:           5
    batch_size:            32
    epochs:                10

SYNOP1:
  notebook:      SYNOP/SYNOP1-Preparation-of-data.ipynb
  overrides:
    output_dir:            default

SYNOP2:
  notebook:      SYNOP/SYNOP2-First-predictions.ipynb
  after:         SYNOP1
  overrides:
    scale:                 1
    train_prop:            0.8
    sequence_len:          16
    batch_size:            32
    epochs:                10
    fit_verbosity:         2

SYNOP3:
  notebook:      SYNOP/SYNOP3-12h-predictions.ipynb
  after:         SYNOP2
  overrides:
    iterations:            4
    scale:                 1
    train_prop:            0.8
    sequence_len:          16

#
# ------------ Transformers
#
# TRANS1:
#   notebook:      Transformers/01-Distilbert.ipynb
#
# TRANS2:
#   notebook:      Transformers/02-distilbert_colab.ipynb

#
# ------------ AE
#
AE1:
  notebook:      AE/01-Prepare-MNIST-dataset.ipynb
  overrides:
    prepared_dataset:      default
    scale:                 1
    progress_verbosity:    2

AE2:
  notebook:      AE/02-AE-with-MNIST.ipynb
  after:         AE1
  overrides:
    prepared_dataset:      default
    dataset_seed:          123
    scale:                 1
    latent_dim:            10
    train_prop:            0.8
    batch_size:            128
    epochs:                30
    fit_verbosity:         2

AE3:
  notebook:      AE/03-AE-with-MNIST-post.ipynb
  after:         AE2
  overrides:
    prepared_dataset:      default
    dataset_seed:          123
    scale:                 1
    train_prop:            0.8

AE4:
  notebook:      AE/04-ExtAE-with-MNIST.ipynb
  after:         AE1
  overrides:
    prepared_dataset:      default
    dataset_seed:          default
    scale:                 1
    latent_dim:            10
    train_prop:            0.8
    batch_size:            128
    epochs:                20
    fit_verbosity:         2

AE5:
  notebook:      AE/05-ExtAE-with-MNIST.ipynb
  after:         AE1
  overrides:
    prepared_dataset:      default
    dataset_seed:          default
    scale:                 1
    latent_dim:            10
    train_prop:            0.8
    batch_size:            128
    epochs:                30
    fit_verbosity:         2

#
# ------------ VAE
#
VAE1:
  notebook:       VAE/01-VAE-with-MNIST.ipynb
  overrides:
    latent_dim:            2
    loss_weights:          default
    scale:                 1
    seed:                  default
    batch_size:            64
    epochs:                10
    fit_verbosity:         2

VAE2:
  notebook:       VAE/02-VAE-with-MNIST.ipynb
  overrides:
    latent_dim:            6
    loss_weights:          default
    scale:                 1
    seed:                  default
    batch_size:            64
    epochs:                10
    fit_verbosity:         2

VAE3:
  notebook:       VAE/03-VAE-with-MNIST-post.ipynb
  after:          VAE2
  overrides:
    scale:                 1
    seed:                  default
    models_dir:            default

VAE5:
  notebook:       VAE/05-About-CelebA.ipynb
  overrides:
    progress_verbosity:    2

VAE6.1:
  notebook:       VAE/06-Prepare-CelebA-datasets.ipynb
  overrides:
    scale:                 0.02
    seed:                  default
    cluster_size:          10000
    image_size:            (128,128)
    output_dir:            ./data
    exit_if_exist:         False
    progress_verbosity:    2

VAE6.2:
  notebook:       VAE/06-Prepare-CelebA-datasets.ipynb
  overrides:
    scale:                 0.02
    seed:                  default
    cluster_size:          10000
    image_size:            (192,160)
    output_dir:            ./data
    exit_if_exist:         False
    progress_verbosity:    2

VAE7:
  notebook:       VAE/07-Check-CelebA.ipynb
  after:          VAE6.1
  overrides:
    image_size:            (192,160)
    enhanced_dir:          ./data
    progress_verbosity:    2

VAE8:
  notebook:       VAE/08-VAE-with-CelebA-128x128.ipynb
  after:          VAE6.1
  overrides:
    scale:                 1
    image_size:            (128,128)
    enhanced_dir:          '{datasets_dir}/celeba/enhanced'
    latent_dim:            300
    loss_weights:          default
    batch_size:            64
    epochs:                15
    fit_verbosity:         2

VAE9:
  notebook:       VAE/09-VAE-with-CelebA-192x160.ipynb
  after:          VAE6.2
  overrides:
    scale:                 1
    image_size:            (192,160)
    enhanced_dir:          '{datasets_dir}/celeba/enhanced'
    latent_dim:            300
    loss_weights:          default
    batch_size:            64
    epochs:                10
    fit_verbosity:         2

VAE10.1:
  notebook:      VAE/10-VAE-with-CelebA-post.ipynb
  after:         VAE8
  overrides:
    image_size:            (128,128)
    enhanced_dir:          '{datasets_dir}/celeba/enhanced'
    models_dir:            ./run/VAE8

VAE10.2:
  notebook:      VAE/10-VAE-with-CelebA-post.ipynb
  after:         VAE9
  overrides:
    image_size:            (192,160)
    enhanced_dir:          '{datasets_dir}/celeba/enhanced'
    models_dir:            ./run/VAE9

#
# ------------ DCGAN
#
SHEEP1:
  notebook:      DCGAN/01-DCGAN-Draw-me-a-sheep.ipynb
  overrides:
    scale:                 1
    latent_dim:            128
    epochs:                8
    batch_size:            32
    num_img:               12
    fit_verbosity:         2

SHEEP2:
  notebook:      DCGAN/02-WGANGP-Draw-me-a-sheep.ipynb
  overrides:
    scale:                 1
    latent_dim:            128
    epochs:                4
    batch_size:            64
    num_img:               12
    fit_verbosity:         2

#
# ------------ DRL
#
# DRL1:
#   notebook:      DRL/FIDLE_DQNfromScratch.ipynb

# DRL2:
#   notebook:      DRL/FIDLE_rl_baselines_zoo.ipynb

#
# ------------ Misc
#
ACTF1:
  notebook:      Misc/Activation-Functions.ipynb

NP1:
  notebook:      Misc/Numpy.ipynb

SCRATCH1:
  notebook:      Misc/Scratchbook.ipynb

TSB1:
  notebook:      Misc/Using-Tensorboard.ipynb
