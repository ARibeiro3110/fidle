campain:
  version: '1.0'
  description: Automatically generated ci profile (03/03/24 14:46:51)
  directory: ./campains/default
  existing_notebook: 'remove    # remove|skip'
  report_template: 'fidle     # fidle|default'
  timeout: 6000

#
# ------------ LinearReg
#
LINR1:
  notebook: LinearReg/01-Linear-Regression.ipynb
GRAD1:
  notebook: LinearReg/02-Gradient-descent.ipynb
POLR1:
  notebook: LinearReg/03-Polynomial-Regression.ipynb
LOGR1:
  notebook: LinearReg/04-Logistic-Regression.ipynb

#
# ------------ Perceptron
#
PER57:
  notebook: Perceptron/01-Simple-Perceptron.ipynb

#
# ------------ BHPD.Keras3
#
K3BHPD1:
  notebook: BHPD.Keras3/01-DNN-Regression.ipynb
  overrides:
    fit_verbosity: default
K3BHPD2:
  notebook: BHPD.Keras3/02-DNN-Regression-Premium.ipynb
  overrides:
    fit_verbosity: default

#
# ------------ BHPD.PyTorch
#
PBHPD1:
  notebook: BHPD.PyTorch/01-DNN-Regression_PyTorch.ipynb

#
# ------------ Wine.Keras3
#
K3WINE1:
  notebook: Wine.Keras3/01-DNN-Wine-Regression.ipynb
  overrides:
    fit_verbosity: default
    dataset_name: default

#
# ------------ Wine.Lightning
#
LWINE1:
  notebook: Wine.Lightning/01-DNN-Wine-Regression-lightning.ipynb
  overrides:
    fit_verbosity: default
    dataset_name: default

#
# ------------ MNIST.Keras3
#
K3MNIST1:
  notebook: MNIST.Keras3/01-DNN-MNIST.ipynb
  overrides:
    fit_verbosity: default
K3MNIST2:
  notebook: MNIST.Keras3/02-CNN-MNIST.ipynb
  overrides:
    fit_verbosity: default

#
# ------------ MNIST.PyTorch
#
PMNIST1:
  notebook: MNIST.PyTorch/01-DNN-MNIST_PyTorch.ipynb

#
# ------------ MNIST.Lightning
#
LMNIST1:
  notebook: MNIST.Lightning/01-DNN-MNIST_Lightning.ipynb
LMNIST2:
  notebook: MNIST.Lightning/02-CNN-MNIST_Lightning.ipynb

#
# ------------ GTSRB.Keras3
#
K3GTSRB1:
  notebook: GTSRB.Keras3/01-Preparation-of-data.ipynb
  overrides:
    scale: default
    output_dir: default
    progress_verbosity: default
K3GTSRB2:
  notebook: GTSRB.Keras3/02-First-convolutions.ipynb
  overrides:
    enhanced_dir: default
    dataset_name: default
    batch_size: default
    epochs: default
    scale: default
    fit_verbosity: default
K3GTSRB3:
  notebook: GTSRB.Keras3/03-Better-convolutions.ipynb
  overrides:
    enhanced_dir: default
    model_name: default
    dataset_name: default
    batch_size: default
    epochs: default
    scale: default
    fit_verbosity: default
K3GTSRB4:
  notebook: GTSRB.Keras3/04-Keras-cv.ipynb

#
# ------------ Embedding.Keras3
#
K3IMDB1:
  notebook: Embedding.Keras3/01-One-hot-encoding.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    batch_size: default
    epochs: default
    fit_verbosity: default
K3IMDB2:
  notebook: Embedding.Keras3/02-Keras-embedding.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    review_len: default
    dense_vector_size: default
    batch_size: default
    epochs: default
    output_dir: default
    fit_verbosity: default
K3IMDB3:
  notebook: Embedding.Keras3/03-Prediction.ipynb
  overrides:
    vocab_size: default
    review_len: default
    saved_models: default
    dictionaries_dir: default
K3IMDB4:
  notebook: Embedding.Keras3/04-Show-vectors.ipynb
  overrides:
    vocab_size: default
    review_len: default
    saved_models: default
    dictionaries_dir: default
K3IMDB5:
  notebook: Embedding.Keras3/05-LSTM-Keras.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    review_len: default
    dense_vector_size: default
    batch_size: default
    epochs: default
    fit_verbosity: default
    scale: default

#
# ------------ RNN.Keras3
#
K3LADYB1:
  notebook: RNN.Keras3/01-Ladybug.ipynb
  overrides:
    scale: default
    train_prop: default
    sequence_len: default
    predict_len: default
    batch_size: default
    epochs: default

#
# ------------ Transformers.PyTorch
#
TRANS1:
  notebook: Transformers.PyTorch/01-Distilbert.ipynb
TRANS2:
  notebook: Transformers.PyTorch/02-distilbert_colab.ipynb

#
# ------------ AE.Keras3
#
AE1:
  notebook: AE.Keras3/01-Prepare-MNIST-dataset.ipynb
  overrides:
    prepared_dataset: default
    scale: default
    progress_verbosity: default
AE2:
  notebook: AE.Keras3/02-AE-with-MNIST.ipynb
  overrides:
    prepared_dataset: default
    dataset_seed: default
    scale: default
    latent_dim: default
    train_prop: default
    batch_size: default
    epochs: default
    fit_verbosity: default
AE3:
  notebook: AE.Keras3/03-AE-with-MNIST-post.ipynb
  overrides:
    prepared_dataset: default
    dataset_seed: default
    scale: default
    train_prop: default
AE4:
  notebook: AE.Keras3/04-ExtAE-with-MNIST.ipynb
  overrides:
    prepared_dataset: default
    dataset_seed: default
    scale: default
    train_prop: default
    batch_size: default
    epochs: default
    fit_verbosity: default
AE5:
  notebook: AE.Keras3/05-ExtAE-with-MNIST.ipynb
  overrides:
    prepared_dataset: default
    dataset_seed: default
    scale: default
    train_prop: default
    batch_size: default
    epochs: default
    fit_verbosity: default

#
# ------------ VAE.Keras3
#
VAE1:
  notebook: VAE.Keras3/01-VAE-with-MNIST-LossLayer.ipynb
  overrides:
    latent_dim: default
    loss_weights: default
    scale: default
    seed: default
    batch_size: default
    epochs: default
    fit_verbosity: default
VAE2:
  notebook: VAE.Keras3/02-VAE-with-MNIST.ipynb
  overrides:
    latent_dim: default
    loss_weights: default
    scale: default
    seed: default
    batch_size: default
    epochs: default
    fit_verbosity: default
VAE3:
  notebook: VAE.Keras3/03-VAE-with-MNIST-post.ipynb
  overrides:
    scale: default
    seed: default
    models_dir: default

#
# ------------ DCGAN.Lightning
#
SHEEP3:
  notebook: DCGAN.Lightning/01-DCGAN-PL.ipynb
  overrides:
    latent_dim: default
    gan_name: default
    generator_name: default
    discriminator_name: default
    epochs: default
    lr: default
    b1: default
    b2: default
    batch_size: default
    num_img: default
    fit_verbosity: default
    dataset_file: default
    data_shape: default
    scale: default

#
# ------------ DDPM.PyTorch
#
DDPM1:
  notebook: DDPM.PyTorch/01-ddpm.ipynb

#
# ------------ Optimization.PyTorch
#
OPT1:
  notebook: Optimization.PyTorch/01-Apprentissages-rapides-et-Optimisations.ipynb

#
# ------------ DRL.PyTorch
#
DRL1:
  notebook: DRL.PyTorch/FIDLE_DQNfromScratch.ipynb
DRL2:
  notebook: DRL.PyTorch/FIDLE_rl_baselines_zoo.ipynb

#
# ------------ Misc
#
NP1:
  notebook: Misc/00-Numpy.ipynb
ACTF1:
  notebook: Misc/01-Activation-Functions.ipynb
PANDAS1:
  notebook: Misc/02-Using-pandas.ipynb
PYTORCH1:
  notebook: Misc/03-Using-Pytorch.ipynb
TSB1:
  notebook: Misc/04-Using-Tensorboard.ipynb
  overrides: ??
??:
  notebook: Misc/05-RNN.ipynb
