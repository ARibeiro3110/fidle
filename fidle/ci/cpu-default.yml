campain:
  version:            '1.0'
  description:         Notebook test on CPU, default settings.
  directory:          ./campains/cpu-default
  existing_notebook:  'remove'    # remove|skip
  report_template:    'fidle'     # fidle|default
  timeout: 6000

  environment_vars:
    FIDLE_SAVE_FIGS:         true


#
# ------------ LinearReg
#
LINR1:
  notebook: LinearReg/01-Linear-Regression.ipynb

GRAD1:
  notebook: LinearReg/02-Gradient-descent.ipynb

POLR1:
  notebook: LinearReg/03-Polynomial-Regression.ipynb

LOGR1:
  notebook: LinearReg/04-Logistic-Regression.ipynb

#
# ------------ Perceptron
#
PER57:
  notebook: Perceptron/01-Simple-Perceptron.ipynb

#
# ------------ BHPD.Keras3
#
K3BHPD1:
  notebook: BHPD.Keras3/01-DNN-Regression.ipynb
  overrides:
    fit_verbosity: 2

K3BHPD2:
  notebook: BHPD.Keras3/02-DNN-Regression-Premium.ipynb
  overrides:
    fit_verbosity: 2

#
# ------------ BHPD.PyTorch
#
PBHPD1:
  notebook: BHPD.PyTorch/01-DNN-Regression_PyTorch.ipynb

#
# ------------ Wine.Keras3
#
K3WINE1:
  notebook: Wine.Keras3/01-DNN-Wine-Regression.ipynb
  overrides:
    fit_verbosity: 2
    dataset_name: default

#
# ------------ Wine.Lightning
#
LWINE1:
  notebook: Wine.Lightning/01-DNN-Wine-Regression-lightning.ipynb
  overrides:
    fit_verbosity: 2
    dataset_name: default

#
# ------------ MNIST.Keras3
#
K3MNIST1:
  notebook: MNIST.Keras3/01-DNN-MNIST.ipynb
  overrides:
    fit_verbosity: 2

K3MNIST2:
  notebook: MNIST.Keras3/02-CNN-MNIST.ipynb
  overrides:
    fit_verbosity: 2

#
# ------------ MNIST.PyTorch
#
PMNIST1:
  notebook: MNIST.PyTorch/01-DNN-MNIST_PyTorch.ipynb

#
# ------------ MNIST.Lightning
#
LMNIST2:
  notebook: MNIST.Lightning/02-CNN-MNIST_Lightning.ipynb

#
# ------------ GTSRB.Keras3
#
K3GTSRB1:
  notebook: GTSRB.Keras3/01-Preparation-of-data.ipynb
  overrides:
    scale: default
    output_dir: default
    progress_verbosity: default

K3GTSRB2:
  notebook: GTSRB.Keras3/02-First-convolutions.ipynb
  after:    K3GTSRB1
  overrides:
    enhanced_dir: default
    dataset_name: default
    batch_size: default
    epochs: default
    scale: default
    fit_verbosity: 2

K3GTSRB3:
  notebook: GTSRB.Keras3/03-Better-convolutions.ipynb
  after:    K3GTSRB1
  overrides:
    enhanced_dir: default
    model_name: default
    dataset_name: default
    batch_size: default
    epochs: default
    scale: default
    fit_verbosity: 2

#
# ------------ Embedding.Keras3
#
K3IMDB1:
  notebook: Embedding.Keras3/01-One-hot-encoding.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    batch_size: default
    epochs: default
    fit_verbosity: 2

K3IMDB2:
  notebook: Embedding.Keras3/02-Keras-embedding.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    review_len: default
    dense_vector_size: default
    batch_size: default
    epochs: default
    output_dir: default
    fit_verbosity: 2

K3IMDB3:
  notebook: Embedding.Keras3/03-Prediction.ipynb
  after:    K3IMDB2
  overrides:
    vocab_size: default
    review_len: default
    saved_models: default
    dictionaries_dir: default

K3IMDB4:
  notebook: Embedding.Keras3/04-Show-vectors.ipynb
  after:    K3IMDB2
  overrides:
    vocab_size: default
    review_len: default
    saved_models: default
    dictionaries_dir: default

K3IMDB5:
  notebook: Embedding.Keras3/05-LSTM-Keras.ipynb
  overrides:
    vocab_size: default
    hide_most_frequently: default
    review_len: default
    dense_vector_size: default
    batch_size: default
    epochs: default
    fit_verbosity: 2
    scale: default

#
# ------------ RNN.Keras3
#
K3LADYB1:
  notebook: RNN.Keras3/01-Ladybug.ipynb
  overrides:
    scale: default
    train_prop: default
    sequence_len: default
    predict_len: default
    batch_size: default
    epochs: default

#
# ------------ Misc
#
NP1:
  notebook: Misc/00-Numpy.ipynb

ACTF1:
  notebook: Misc/01-Activation-Functions.ipynb

PANDAS1:
  notebook: Misc/02-Using-pandas.ipynb